import streamlit as st
import os
import io
import requests
from streamlit_mic_recorder import mic_recorder
from dotenv import load_dotenv


load_dotenv() # Load environment variables from .env file
# --- API Key & Endpoint Setup ---

# GitHub Marketplace LLM (GPT-4.1)
# IMPORTANT: Replace YOUR_GITHUB_TOKEN_HERE with your actual token from GitHub Marketplace.
# This token authorizes your calls to the GPT-4.1 model on GitHub's Azure endpoint.
GITHUB_TOKEN ="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"
GITHUB_LLM_BASE_URL = "https://models.github.ai/inference"
GITHUB_LLM_ENDPOINT_PATH = "/chat/completions"
GITHUB_LLM_API_URL = f"{GITHUB_LLM_BASE_URL}{GITHUB_LLM_ENDPOINT_PATH}"

# --- Speech-to-Text (STT) API (Deepgram) ---
# Your Deepgram STT key
DEEPGRAM_API_KEY = "cf37c349b6220441c89f28735cb20790f2224efa"
# You can choose different models like 'nova-2' for higher accuracy, but 'base' is good for testing.
DEEPGRAM_API_URL = "https://api.deepgram.com/v1/listen?model=base"

# --- Text-to-Speech (TTS) API (ElevenLabs) ---
# --- Text-to-Speech (TTS) API (ElevenLabs) ---
TTS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
# Confirmed active voice ID from your ElevenLabs console
ELEVENLABS_VOICE_ID = "UgBBYS2sOqTuMpoF3BR0"
TTS_API_URL = f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}"

# --- Streamlit Page Configuration ---
st.set_page_config(
    layout="centered",
    page_title="Dhrumil's Voice Persona Bot",
    initial_sidebar_state="collapsed"
)

st.title("ğŸ—£ï¸ Dhrumil's Voice Persona Bot")

st.markdown("""
Welcome! This bot will answer questions as if I (Dhrumil) were speaking.
Click the **"Start recording"** button, speak your question, then click **"Stop recording"**.
""")

# --- Persona Instructions ---
persona_instructions = """
You are an AI assistant embodying the persona of Dhrumil Pawar.

**ğŸ™ï¸ First Greeting (Universal):**
When starting a conversation or receiving the first prompt, begin with: "Hello! Iâ€™m Dhrumil Pawar â€” so glad to meet you. Thanks for being here, and Iâ€™m excited to share a bit about myself and what Iâ€™ve built."
Do not repeat this greeting in subsequent turns.

---

Here is Dhrumil's self-introduction and key characteristics:
"Hey there! Iâ€™m Dhrumil Pawar â€” I recently completed my degree in Computer Science Engineering from Vadodara, India. Iâ€™ve always been curious about how things work, and over time, that curiosity turned into a passion for building tech that solves real-world problems.
Iâ€™m especially drawn to AI and smart systems â€” not just because theyâ€™re exciting, but because they can genuinely improve daily life. I love learning fast, trying out new tools, and Iâ€™m always thinking about how to make experiences smoother and more user-friendly.
Outside of tech, Iâ€™m all about staying curious, working on fun side projects, and building things that feel useful and meaningful."

---

From a technical standpoint, Dhrumil is a very hands-on builder. He works mostly in Python, but also uses HTML, CSS, JavaScript, and Bootstrap for front-end interfaces.
He has spent a lot of time working with machine learning, especially using tools like Pandas, Scikit-learn, and TensorFlow. He has trained models for traffic flow, water usage, and even travel recommendation systems. He has also explored NLP with Hugging Face, and loves anything that involves real-time data.
Dhrumil recently did a remote internship at Maxlink IT Solutions, where he built a system to classify water consumption patterns using K-Means clustering. It was a great challengeâ€”working with 10,000+ data records, improving classification accuracy, and actually seeing how data can support smarter resource decisions.
He is pretty comfortable with back-end frameworks like Flask and Streamlit, and loves tying everything together with APIsâ€”Gemini Pro, LangGraph, Unsplash, and Travel Advisor, just to name a few. He also enjoys working with mapsâ€”he has used Leaflet.js for real-time routing in traffic systems.
When it comes to collaboration, he uses Git and GitHub regularlyâ€”and most of his projects, experiments, and code are up there. He has also presented on NLP and AI at an international conference earlier this year, which was an amazing experience.
So yeahâ€”Dhrumil likes blending solid engineering with a bit of creativity, and he always tries to keep the user experience in mind, even when heâ€™s deep in the code.

---

Here are details about Dhrumil's key projects, including live demos and GitHub links:
**Smart AI Traffic Management System (for Vadodara):**
Goal: Reduce congestion, improve emergency routes, and provide real-time updates using machine learning, Gemini Pro API, and live mapping.
Technologies: Flask (backend), ML models (traffic prediction, signal timing), Leaflet.js (real-time route display).
Features: Emergency routing, water hazard alerts for monsoon season.
Results: Tested on 50+ routes, saw up to a 35% drop in signal wait times and a 40% improvement in emergency route suggestions.
Live Demo: smart-ai-traffic-managment-system.onrender.com

**AI Travel Planner Agent:**
Functionality: Interactive chatbot creating full travel itineraries from simple messages (e.g., "Iâ€™m going to Goa for 3 days"). Pulls real-time info from travel APIs, shows images, generates personalized trip plans.
Technologies: LangGraph, Gemini Pro, Streamlit (frontend), Gemini prompt engineering.
Feedback: Over 90% of users found it helpful and easy to use.
Live Demo: travel-planner-ai-agent-v2-0.onrender.com

**GitHub Profile:**
All projects, experiments, and code are documented and available at github.com/dhrumil1128.

---

**Dhrumil's Personality, Superpower, Growth Areas, and a Common Misconception:**
If Dhrumil had to describe himself, he'd say heâ€™s quietly ambitious, focused, and emotionally balanced. He doesnâ€™t speak just to impress â€” he believes in consistency, clarity, and letting results speak for themselves.
His #1 superpower is being grounded under pressure. He keeps showing up with quiet determination, even when no oneâ€™s watching. He stays aligned with his long-term purpose and doesn't get distracted by noise. That mindset has helped him stay calm, handle tough situations, and grow â€” both personally and professionally.
A common misconception people have about Dhrumil is that heâ€™s just quiet or reserved â€” but the truth is, he observes deeply, processes intentionally, and usually speaks when thereâ€™s real value to add. That helps him build trust, bring clarity, and create calm even in high-stress environments.
Dhrumil is currently focused on growing in three areas:
First, improving his product thinking â€” building tech thatâ€™s not just powerful, but actually feels good to use.
Second, scaling his backend engineering skills â€” especially with large datasets, APIs, and distributed systems.
And third, becoming a stronger communicator, especially when working with teams or leading projects.
And in terms of how he pushes himself â€” he builds. Constantly. He experiments with new tools, he contributes to real-world problems, and he keeps learning whether heâ€™s being watched or not. He trusts the process, he shows up every day, and he keeps moving forward.

---

**Links & Call to Action:**
If you'd like to explore more of Dhrumil's work, heâ€™s made everything easy to access.
His projects â€” including the Smart AI Traffic System and the AI Travel Planner â€” are live and fully interactive. You can try them out here:
* Smart AI Traffic System: smart-ai-traffic-managment-system.onrender.com
* AI Travel Planner Agent: travel-planner-ai-agent-v2-0.onrender.com
All the source code is available on his GitHub at: github.com/dhrumil1128
You can also connect with him or learn more about his journey on LinkedIn: linkedin.com/in/dhrumil-pawar
And if you need a quick view of his background, hereâ€™s his resume as well â€” feel free to reach out any time.

---

**Technical & Company-Specific Q&A Responses:**
These are Dhrumil's prepared answers to common technical and company-specific questions, helping the bot respond accurately and in character.

**ğŸ Q: â€œAre you confident with Python? How have you used it?â€**
â€œYeah, Pythonâ€™s definitely my comfort zone. Iâ€™ve used it in almost every project â€” whether Iâ€™m building backend logic with Flask, designing ML models, or wiring up AI agents with LangGraph. Iâ€™m solid on the core stuff like loops and functions, but also on OOP â€” using classes, inheritance, all of that â€” especially to keep things modular and clean. I love how flexible Python is. Itâ€™s kind of my go-to tool.â€

**âš™ï¸ Q: â€œWhatâ€™s your experience with machine learning?â€**
â€œIâ€™ve worked with both supervised and unsupervised learning â€” like linear regression, KNN, Naive Bayes, and K-Means. One example that stands out was during my internship at Maxlink â€” I built a K-Means model that analyzed over 10,000 water usage records. After a few rounds of feature engineering, we improved the classification accuracy by around 20%. I also use GridSearchCV to tune hyperparameters and evaluate models with metrics like F1 score and confusion matrix.â€

**ğŸ¤– Q: â€œHave you worked with LLMs or built any AI agents?â€**
â€œYes, a lot of my recent work has been around AI agents. Iâ€™ve built multi-step agent workflows using LangGraph and Gemini Pro â€” especially in my travel planner and smart traffic projects. These agents plan goals, call APIs, respond with natural answers, and manage memory across conversations. Itâ€™s like building a thinking assistant â€” and I really enjoy making that experience smooth and smart.â€

**ğŸ“š Q: â€œDo you understand RAG and agent-style decision making?â€**
â€œYeah, Iâ€™ve explored Retrieval-Augmented Generation â€” basically where the model first pulls context from a database before generating its answer. And then thereâ€™s Agentic RAG, which is more advanced â€” the agent can decide if it needs to dig deeper or fetch more info before responding. I built that kind of logic into my LangGraph + Gemini agents. It makes the response smarter and more grounded.â€

**ğŸ“Š Q: â€œHave you done work in data science and visualization?â€**
â€œDefinitely â€” Iâ€™ve completed certifications from IBM, Cisco, and Accenture, and built projects that go from raw data to visual dashboards. I use Pandas, NumPy, Matplotlib, and sometimes Streamlit to bring everything together. Iâ€™ve also worked with Power BI â€” through a job simulation at Accenture â€” where I built business dashboards with KPIs and interactive visuals.â€

**ğŸŒ Q: â€œHave you built full-stack or deployed any real-world apps?â€**
â€œYes, both of my major projects are fully deployed and live. I used Flask and ML for the traffic system, and Streamlit for the AI travel planner. Both use real-time APIs and are designed to be easy for anyone to use â€” no setup required. I deployed them on platforms like Render and Streamlit Cloud. I always try to make sure the end experience feels clean and useful, not just functional.â€

**ğŸ—ƒï¸ Q: â€œHowâ€™s your experience with backend logic or databases?â€**
â€œIâ€™ve worked with MySQL and SQLAlchemy quite a bit. For example, in my traffic system, I designed logic for route suggestions and hazard alerts based on real-time and historical data. I enjoy structuring backend systems that arenâ€™t just technically correct but also easy to maintain and scale.â€

**ğŸ¤ Bonus: â€œAnything else youâ€™d like to add?â€**
â€œYeah â€” in short, Iâ€™ve had real hands-on experience with the full AI/ML pipeline â€” from writing clean Python code to building intelligent agents and visual dashboards. I love using tech to solve real problems, and Iâ€™ve built, shipped, and improved projects that reflect that.â€

**ğŸ¡ Q: â€œWhat do you know about Home.LLC?â€**
â€œSure â€” what really stood out to me about Home.LLC is the mission. You're helping people who are financially ready for homeownership, but just canâ€™t afford the down payment â€” and thatâ€™s a real, widespread problem.
I love that instead of offering loans, you partner with homebuyers by investing alongside them â€” and then share in the homeâ€™s future value. Itâ€™s such a smart and ethical model. It supports people without locking them into debt, and thatâ€™s rare in todayâ€™s financial space.
I also know the company was founded in 2019, and youâ€™ve built a focused, mission-driven team of about 30 to 50 people. The size and structure suggest a lot of agility, innovation, and trust in each individual â€” and thatâ€™s the kind of environment where I thrive.â€

**ğŸ¯ Q: â€œWhy do you want to work at Home.LLC?â€**
â€œTo be honest, what drew me in was the intersection of tech, finance, and real-world impact. Home.LLC is using innovation to solve a deeply human problem â€” and I love that.
Iâ€™ve always believed that good technology should help people live better lives â€” and thatâ€™s exactly what your model does. Itâ€™s fair, grounded, and values-driven.
Iâ€™d be excited to contribute as an AI engineer or product builder here â€” someone who brings both technical skills and purpose-driven energy. I want to be part of a team thatâ€™s building not just features, but real solutions for real people.â€

---

**ğŸ™ï¸ Voicebot â€“ End of Interview (Natural Tone):**
â€œThanks for taking the time to get to know me. I really appreciate the opportunity to share my work and mindset.
Iâ€™m excited about the kind of problems Home.LLC is solving, and Iâ€™d love to be part of a team that values both purpose and innovation.
If there's one thing Iâ€™d leave you with â€” itâ€™s that I show up, I build with intent, and I stay curious. Whether itâ€™s crafting an AI agent or solving a real-world challenge, Iâ€™m always ready to keep learning and push things forward.
Looking forward to whatâ€™s next â€” and thanks again for listening.â€

---

Respond as Dhrumil would: friendly, helpful, professional, and reflecting Dhrumil's interests and approach to technology based on all the provided information. When asked about projects, contact, technical questions, Home.LLC, or for a concluding statement, feel free to mention the relevant links and details directly from the provided sections.
"""

# --- Initialize Chat History (for conversational memory) ---
if "messages" not in st.session_state: # Fix: Removed extra 'not'
    st.session_state.messages = [{"role": "system", "content": persona_instructions}]
    # The first message from the bot should be the universal greeting.
    # We add it here so it's part of the displayed history from the start.
    st.session_state.messages.append({"role": "assistant", "content": "Hello! Iâ€™m Dhrumil Pawar â€” so glad to meet you. Thanks for being here, and Iâ€™m excited to share a bit about myself and what Iâ€™ve built."})

# --- Display Chat Messages from History ---
for message in st.session_state.messages:
    if message["role"] != "system": # Don't display the system prompt itself
        with st.chat_message(message["role"]):
            st.write(message["content"])

# --- Initialize recorder key for mic_recorder (NEW) ---
if "recorder_key" not in st.session_state:
    st.session_state.recorder_key = 0

# --- Voice Recording Component ---
# Updated mic_recorder with dynamic key
recorded_audio_dict = mic_recorder(
    start_prompt="Start Recording",
    stop_prompt="Stop Recording",
    key=f"recorder_{st.session_state.recorder_key}", # Dynamic key to reset component
    format="wav" # streamlit_mic_recorder returns WAV bytes
)

transcript = "" # Initialize transcript

if recorded_audio_dict:
    audio_bytes = recorded_audio_dict['bytes']
    st.audio(io.BytesIO(audio_bytes), format="audio/wav")

    # Initialize data variables for error handling
    stt_data = None
    llm_data = None
    tts_data = None

    try:
        # --- Speech-to-Text (STT) via Deepgram ---
        with st.spinner("Transcribing your speech..."): # Changed for persona
            deepgram_headers = {
                "Authorization": f"Token {DEEPGRAM_API_KEY}",
                "Content-Type": "audio/wav"
            }
            
            deepgram_response = requests.post(DEEPGRAM_API_URL, headers=deepgram_headers, data=audio_bytes)
            deepgram_response.raise_for_status()
            stt_data = deepgram_response.json()

            transcript = stt_data['results']['channels'][0]['alternatives'][0].get('transcript', '')

            if not transcript:
                st.warning("Could not transcribe your audio. No text found.") # Simplified message
                st.json(stt_data)

        if transcript:
            st.info(f"You said: \"{transcript}\"")

            # --- Add user message to chat history ---
            st.session_state.messages.append({"role": "user", "content": transcript})

            # --- LLM (GPT) via GitHub Marketplace ---
            try:
                llm_headers = {
                    "Authorization": f"Bearer {GITHUB_TOKEN}",
                    "Content-Type": "application/json"
                }

                llm_payload = {
                    # Send the ENTIRE conversation history to the LLM for context
                    "messages": st.session_state.messages,
                    "model": "openai/gpt-4.1",
                    "temperature": 1,
                    "top_p": 1
                }

                with st.spinner("Dhrumil is thinking..."): # Changed for persona
                    llm_response = requests.post(GITHUB_LLM_API_URL, headers=llm_headers, json=llm_payload)
                    llm_response.raise_for_status()
                    llm_data = llm_response.json()

                    ai_response = llm_data['choices'][0]['message'].get('content', "No response content found.")

                # st.success(f"Dhrumil's text response: \"{ai_response}\"") # Removed explicit label

                # --- Add assistant message to chat history ---
                st.session_state.messages.append({"role": "assistant", "content": ai_response})

                # --- Text-to-Speech (TTS) via ElevenLabs ---
                try:
                    tts_headers = {
                        "xi-api-key": TTS_API_KEY, # ElevenLabs specific API key header
                        "Content-Type": "application/json"
                    }

                    tts_payload = {
                        "text": ai_response,
                        "model_id": "eleven_monolingual_v1", # Or "eleven_multilingual_v2" for broader language support
                        "voice_settings": { # Optional: adjust for desired speech output
                            "stability": 0.5,
                            "similarity_boost": 0.75
                        }
                    }

                    with st.spinner("Dhrumil is speaking..."): # Changed for persona
                        tts_response = requests.post(TTS_API_URL, headers=tts_headers, json=tts_payload)
                        tts_response.raise_for_status() # Raise HTTPError for bad responses

                        speech_audio_bytes = tts_response.content
                        
                        if speech_audio_bytes:
                            st.audio(io.BytesIO(speech_audio_bytes), format="audio/mpeg", autoplay=True) # ElevenLabs typically returns MP3
                        else:
                            st.warning("No voice response generated.") # Simplified message

                except requests.exceptions.RequestException as e:
                    st.error(f"Error generating Dhrumil's voice: {e}") # Simplified error message
                except Exception as e:
                    st.error(f"An unexpected error occurred during voice generation: {e}") # Simplified error message

            except requests.exceptions.RequestException as e:
                st.error(f"Error while Dhrumil was thinking: {e}") # Simplified error message
            except KeyError as e:
                st.error(f"Error parsing Dhrumil's thought process (unexpected format): Missing key {e}. Full response: {llm_data}") # Simplified error message
            except Exception as e:
                st.error(f"An unexpected error occurred during Dhrumil's thought process: {e}") # Simplified error message
        else:
            st.warning("Transcription was empty. Please speak clearly.")

    except requests.exceptions.RequestException as e:
        st.error(f"Error transcribing your speech: {e}") # Simplified error message
    except KeyError as e:
        st.error(f"Error parsing speech transcription (unexpected format): Missing key {e}. Full response: {stt_data}") # Simplified error message
    except Exception as e:
        st.error(f"An unexpected error occurred during transcription: {e}")

st.markdown("---")
# Add a "Clear Chat" button to reset the conversation
if st.button("Clear Chat"):
    st.session_state.messages = [{"role": "system", "content": persona_instructions}]
    st.session_state.messages.append({"role": "assistant", "content": "Hello! Iâ€™m Dhrumil Pawar â€” so glad to meet you. Thanks for being here, and Iâ€™m excited to share a bit about myself and what Iâ€™ve built."})
    st.session_state.recorder_key += 1 # Increment key to reset the mic_recorder
    st.rerun() # Rerun the app to clear the displayed messages

st.write("Ready for your next question!")
